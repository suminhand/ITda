{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHEPTER 4 신경망 학습\n",
    "---\n",
    "- 학습: 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것.\n",
    "- 손실 함수: 신경망이 학습할 수 있도록 해주는 지표  \n",
    "    -> 손실함수의 결괏값을 가장 작게 만들어야 함.\n",
    "- 경사법: 함수의 기울기를 활용하여 손실 함수의 값을 가급적 작게 만드는 것.\n",
    "\n",
    "## 4.1 데이터에서 학습한다!\n",
    "\n",
    "- 신경망은 데이터를 보고 학습할 수 있다는 특징을 갖는다.  \n",
    "    즉, 가중치 매개변수의 값이 데이터를 보고 자동으로 결정이 된다.\n",
    "\n",
    "### 4.1.1 데이터 주도 학습\n",
    "\n",
    "- 기계학습: 데이터에서 답을 찾고 패턴을 발견하고 이야기를 만드는 것. 데이터 매우 중요!!  \n",
    "    -> 데이터가 이끄는 접근 방식 덕에 사람 중심 접근에서 벗어날 수 있었음.\n",
    "\n",
    "- 문제를 해결하는 방법  \n",
    "    -> 기존 프로그램: 문제 - 사람이 생각한 알고리즘 - 결과  \n",
    "    -> 기계 학습: 문제 - 사람이 생각한 특징(SIFT, HOG 등) - 기계학습(SVM, KNN 등) - 결과  \n",
    "    -> 신경망(딥러닝): 문제 - 신경망(딥러닝) - 결과\n",
    "\n",
    "- 기계 학습은 '사람'이 적절한 특징을 생각해 내고 모아진 데이터로부터 기계학습을 통해 규칙을 찾아내야 했음.\n",
    "- 신경망은 이미지를 '있는 그대로' 학습. 사람이 생각했던 특징들까지 '기계' 스스로 학습 (=> 종단간 기계학습(end-to-end machine learning)이라고도 함.)\n",
    "\n",
    "### 4.1.2 훈련 데이터와 시험 데이터\n",
    "\n",
    "- 기계 데이터를 취급할 때 주의할 점  \n",
    "범용 능력(아직 보지 못한 데이터로 문제를 올바르게 풀어내는 능력)을 제대로 평가하기 위해 훈련 데이터와 시험 데이터를 분리한다.\n",
    "    - 훈련 데이터: 최적의 매개변수를 찾기 위한 데이터\n",
    "    - 시험 데이터: 앞서 훈련한 모델의 실력을 평가하기 위한 데이터  \n",
    "(오버피팅: 한 데이터셋에만 지나치게 최적화된 상태)\n",
    "\n",
    "\n",
    "## 4.2 손실 함수\n",
    "\n",
    "- 신경망에서는 '하나의 지표'를 기준으로 최적의 매개변수 값을 탐색하는데, 신경망 학습에서 사용하는 지표를 손실함수라고 한다.  \n",
    "    손실함수는 일반적으로 오차제곱합과 교차 엔트로피 오차를 사용.  \n",
    "\n",
    "### 4.2.1 오차제곱합\n",
    "\n",
    "- 원-핫 인코딩: 한 원소만 1로 하고 그 외에는 0으로 나타내는 표기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차제곱합\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def sum_squares_error(y, t):    # y, t는 넘파이 배열\n",
    "    return 0.5 * np.sum((y - t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09750000000000003\n",
      "0.5975\n"
     ]
    }
   ],
   "source": [
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # 정답은 '2'\n",
    "\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]    # 2일 확률이 가장 높다고 추정\n",
    "\n",
    "print(sum_squares_error(np.array(y), np.array(t)))\n",
    "\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]    # 7일 확률이 가장 높다고 추정\n",
    "\n",
    "print(sum_squares_error(np.array(y), np.array(t)))\n",
    "\n",
    "# 첫 번째 예의 추정 결과가 호차가 더 작으므로 정답에 더 가까울 것임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 교차 엔트로피 오차\n",
    "\n",
    "- 교차 엔트로피 오차는 정답일 때의 출력이 전체 값을 정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 엔트로피 오차\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def coross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y +delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302584092994546"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "coross_entropy_error(np.array(y), np.array(t))\n",
    "\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0] \n",
    "coross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 미니배치 학습\n",
    "\n",
    "- 미니배치: 훈련 데이터로부터 일부만 골라 학습을 수행하는 것\n",
    "- 미니배치 학습: 많은 데이터 중 일부만을 가지고 학습하는 학습 방법\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5 왜 손실 함수를 설정하는가?\n",
    "\n",
    "신경망 학습에서는 최적의 배개변수(가중치와편향)를 탐색할 때 손실 함수의 값을 가능한 한 작게 하는 매개변수 값을 찾는다.  \n",
    "이때 매개변수의 미분(기울기)를 계산하고, 그 미분 값을 단서로 매개변수의 값을 서서히 갱신하는 과정 반복.  \n",
    "\n",
    "- 지표로 정확도를 사용하게 되면 매개변수의 미분이 대부분의 장소에서 0이 되므로 사용하지 않는다.( 연속이 아니라 불연속적인 값을 가지므로)  \n",
    "    이는 활성화 함수로 계단 함수를 사용하지 않는 이유와도 들어맞는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b56d81be1da47737d30b70aa2710d8212e04ec4e94145155b43b9ead9b79838"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
